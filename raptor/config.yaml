clustering:
  n_init: 3
  reduced_dim: 10
  max_cluster_tokens: 1024
  max_cluster_size: 5

embedding_model:
  model_id: Alibaba-NLP/gte-large-en-v1.5
  dims: 1024
  batch_size: 4

reranker_model:
  model_id: BAAI/bge-reranker-large

language_model:
  endpoint: http://localhost:8000/v1
  key: token
  model_id: meta-llama/Meta-Llama-3-8B-Instruct
  batch_size: 128

tree_builder:
  tokenizer_id: meta-llama/Meta-Llama-3-8B-Instruct
  leaf_text_tokens: 128
  parent_text_tokens: 512
  max_layers: 3

retrieval:
  step1_k: 200
  step2_k: 10
  response_length: 2048
  temperature: 0.6

neo4j:
  uri: <>
  user: <>
  password: <>

HF_TOKEN: <>
