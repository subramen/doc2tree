clustering:
  n_init: 3
  reduced_dim: 10
  max_cluster_tokens: 1024
  max_cluster_size: 5

embedding_model:
  model_id: Alibaba-NLP/gte-large-en-v1.5
  dims: 1024
  batch_size: 32

reranker_model:
  model: avsolatorio/GIST-large-Embedding-v0

language_model:
  endpoint: <vllm url>
  key: "token"
  model_id: "meta-llama/Meta-Llama-3-8B-Instruct"
  batch_size: 256

tree_builder:
  tokenizer_id: 'meta-llama/Meta-Llama-3-8B-Instruct'
  leaf_text_tokens: 128
  parent_text_tokens: 512
  max_layers: 3

retriever:
  retriever_k: 30
  reranker_k: 5

neo4j:
  uri: <>
  user: <>
  password: <>
